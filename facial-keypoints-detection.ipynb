{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport keras\nfrom math import sin, cos, pi\nimport cv2\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:51.721874Z","iopub.execute_input":"2023-01-20T20:10:51.722178Z","iopub.status.idle":"2023-01-20T20:10:56.939483Z","shell.execute_reply.started":"2023-01-20T20:10:51.722113Z","shell.execute_reply":"2023-01-20T20:10:56.938497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:56.943472Z","iopub.execute_input":"2023-01-20T20:10:56.943961Z","iopub.status.idle":"2023-01-20T20:10:58.015278Z","shell.execute_reply.started":"2023-01-20T20:10:56.943933Z","shell.execute_reply":"2023-01-20T20:10:58.011137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    horizontal_flip = False\n    rotation_augmentation = True\n    brightness_augmentation = True\n    shift_augmentation = True\n    random_noise_augmentation = True\n\n    rotation_angles = [12]\n    pixel_shifts = [12]\n    NUM_EPOCHS = 150\n    BATCH_SIZE = 64","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.016090Z","iopub.status.idle":"2023-01-20T20:10:58.016437Z","shell.execute_reply.started":"2023-01-20T20:10:58.016272Z","shell.execute_reply":"2023-01-20T20:10:58.016289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.018503Z","iopub.status.idle":"2023-01-20T20:10:58.019056Z","shell.execute_reply.started":"2023-01-20T20:10:58.018803Z","shell.execute_reply":"2023-01-20T20:10:58.018829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -u \"../input/facial-keypoints-detection/test.zip\"","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.020908Z","iopub.status.idle":"2023-01-20T20:10:58.021442Z","shell.execute_reply.started":"2023-01-20T20:10:58.021194Z","shell.execute_reply":"2023-01-20T20:10:58.021218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -u \"../input/facial-keypoints-detection/training.zip\"","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.023516Z","iopub.status.idle":"2023-01-20T20:10:58.023998Z","shell.execute_reply.started":"2023-01-20T20:10:58.023741Z","shell.execute_reply":"2023-01-20T20:10:58.023765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntrain_file = \"training.csv\"\ntest_file = \"test.csv\"\nidlookup_file = \"../input/facial-keypoints-detection/IdLookupTable.csv\"\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\nidlookup_data = pd.read_csv(idlookup_file)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.025901Z","iopub.status.idle":"2023-01-20T20:10:58.026359Z","shell.execute_reply.started":"2023-01-20T20:10:58.026121Z","shell.execute_reply":"2023-01-20T20:10:58.026143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_sample(image, keypoint, axis, title):\n    image = image.reshape(96, 96)\n    axis.imshow(image, cmap='gray')\n    axis.scatter(keypoint[0::2], keypoint[1::2], marker='x', s=20)\n    plt.title(title) ","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.028203Z","iopub.status.idle":"2023-01-20T20:10:58.028680Z","shell.execute_reply.started":"2023-01-20T20:10:58.028427Z","shell.execute_reply":"2023-01-20T20:10:58.028449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.030523Z","iopub.status.idle":"2023-01-20T20:10:58.030998Z","shell.execute_reply.started":"2023-01-20T20:10:58.030745Z","shell.execute_reply":"2023-01-20T20:10:58.030767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.033489Z","iopub.status.idle":"2023-01-20T20:10:58.034528Z","shell.execute_reply.started":"2023-01-20T20:10:58.034253Z","shell.execute_reply":"2023-01-20T20:10:58.034278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Length of train dataset: {}\".format(len(train_data)))\nprint(\"Length of test dataset: {}\".format(len(test_data)))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.035603Z","iopub.status.idle":"2023-01-20T20:10:58.036411Z","shell.execute_reply.started":"2023-01-20T20:10:58.036167Z","shell.execute_reply":"2023-01-20T20:10:58.036191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.037768Z","iopub.status.idle":"2023-01-20T20:10:58.038623Z","shell.execute_reply.started":"2023-01-20T20:10:58.038378Z","shell.execute_reply":"2023-01-20T20:10:58.038402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_train_data = train_data.dropna()\nprint(clean_train_data.shape)\n\nunclean_train_data = train_data.fillna(method = 'ffill')\nprint(unclean_train_data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.039975Z","iopub.status.idle":"2023-01-20T20:10:58.040815Z","shell.execute_reply.started":"2023-01-20T20:10:58.040570Z","shell.execute_reply":"2023-01-20T20:10:58.040594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images(image_data) -> np.array:\n    images = []\n    for idx, sample in image_data.iterrows():\n        image = np.array(sample['Image'].split(' '), dtype=int)\n        image = np.reshape(image, (96,96,1))\n        images.append(image)\n    images = np.array(images)/255.\n    return images\n\ndef load_keypoints(keypoint_data) -> np.array:\n    keypoint_data = keypoint_data.drop('Image',axis = 1)\n    keypoint_features = []\n    for idx, sample_keypoints in keypoint_data.iterrows():\n        keypoint_features.append(sample_keypoints)\n    keypoint_features = np.array(keypoint_features, dtype = 'float')\n    return keypoint_features","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.042266Z","iopub.status.idle":"2023-01-20T20:10:58.043307Z","shell.execute_reply.started":"2023-01-20T20:10:58.043065Z","shell.execute_reply":"2023-01-20T20:10:58.043088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nclean_train_images = load_images(clean_train_data)\nprint(\"Shape of clean_train_images: {}\".format(clean_train_images.shape))\nclean_train_keypoints = load_keypoints(clean_train_data)\nprint(\"Shape of clean_train_keypoints: {}\".format(clean_train_keypoints.shape))\ntest_images = load_images(test_data)\nprint(\"Shape of test_images: {}\".format(test_images.shape))\n\ntrain_images = clean_train_images\ntrain_keypoints = clean_train_keypoints\n\nfig, axis = plt.subplots()\nplot_sample(train_images[0], train_keypoints[0], axis, 'Sample Image and Keypoints')\n\nunclean_train_images = load_images(unclean_train_data)\nprint(\"Shape of unclean_train_images {}\".format(unclean_train_images.shape))\nunclean_train_keypoints = load_keypoints(unclean_train_data)\nprint(\"Shape of unclean_train_keypoints {}\".format(unclean_train_keypoints.shape))\ntrain_images = np.concatenate((train_images, unclean_train_images))\ntrain_keypoints = np.concatenate((train_keypoints, unclean_train_keypoints))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.044418Z","iopub.status.idle":"2023-01-20T20:10:58.045448Z","shell.execute_reply.started":"2023-01-20T20:10:58.045199Z","shell.execute_reply":"2023-01-20T20:10:58.045223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def left_right_flip(images, keypoints):\n    flipped_keypoints = []\n    flipped_images = np.flip(images, axis=2)\n    for idx, sample_keypoints in enumerate(keypoints):\n        flipped_keypoints.append([96.-coor if idx%2==0 else coor for idx, coor in enumerate(sample_keypoints)])\n    return flipped_images, flipped_keypoints\n\nif config.horizontal_flip:\n    flipped_train_images, flipped_train_keypoints = left_right_flip(clean_train_images, clean_train_keypoints)\n    print(\"Shape of flipped_train_images: {}\".format(flipped_train_images.shape))\n    print(\"Shape of flipped_train_keypoints: {}\".format(np.shape(flipped_train_keypoints)))\n    train_images = np.concatenate((train_images, flipped_train_images))\n    train_keypoints = np.concatenate((train_keypoints, flipped_train_keypoints))\n    fig, axs = plt.subplots()\n    plot_sample(flipped_train_images[0], flipped_train_keypoints[0], axs, \"Horizontally flipped\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.046656Z","iopub.status.idle":"2023-01-20T20:10:58.048209Z","shell.execute_reply.started":"2023-01-20T20:10:58.047952Z","shell.execute_reply":"2023-01-20T20:10:58.047978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rotate_augmentation(images, keypoints):\n    rotated_images, rotated_keypoints = [], []\n    print(\"Augmentation for angles (in degrees): \")\n    for angle in config.rotation_angles:\n        for angle in [-angle, angle]:\n            print(f'{angle}', end=' ')\n            M = cv2.getRotationMatrix2D((48, 48), angle, 1.0)\n            angle_rad = -angle*pi/180\n            for image in images:\n                rotated_image = cv2.warpAffine(image, M, (96, 96), flags=cv2.INTER_CUBIC)\n                rotated_images.append(rotated_image)\n            \n            for keypoint in keypoints:\n                rotated_keypoint = keypoint - 48 # shift points in the plane so the center of rotation is the origin\n                \n                for idx in range(0, len(rotated_keypoint), 2):\n                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad) - rotated_keypoint[idx+1]*sin(angle_rad)\n                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad) + rotated_keypoint[idx+1]*cos(angle_rad)\n                rotated_keypoint += 48\n                rotated_keypoints.append(rotated_keypoint)\n    print(np.shape(rotated_images))\n    return np.reshape(rotated_images, (-1, 96, 96, 1)), rotated_keypoints\n\nif config.rotation_augmentation:\n    rotated_train_images, rotated_train_keypoints = rotate_augmentation(clean_train_images, clean_train_keypoints)\n    print(\"Shape of rotated_images {}\".format(np.shape(rotated_train_images)))\n    print(\"Shape of rotated_keypoints {}\".format(np.shape(rotated_train_keypoints)))\n    train_images = np.concatenate((train_images, rotated_train_images))\n    train_keypoints = np.concatenate((train_keypoints, rotated_train_keypoints))\n    fig, axs = plt.subplots()\n    plot_sample(rotated_train_images[0], rotated_train_keypoints[0], axs, \"Rotated Image\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.049606Z","iopub.status.idle":"2023-01-20T20:10:58.050355Z","shell.execute_reply.started":"2023-01-20T20:10:58.050103Z","shell.execute_reply":"2023-01-20T20:10:58.050127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def alter_brightness(images, keypoints):\n    altered_brightness_images = []\n    inc_brightness_images = np.clip(images*1.2, 0, 1)\n    dec_brightness_images = np.clip(images*0.8, 0, 1)\n    altered_brightness_images.extend(inc_brightness_images)\n    altered_brightness_images.extend(dec_brightness_images)\n    return altered_brightness_images, np.concatenate((keypoints, keypoints))\n\nif config.brightness_augmentation:\n    alter_brightness_train_images, alter_brightness_train_keypoints = alter_brightness(clean_train_images, clean_train_keypoints)\n    print(\"Shape of alter_brightness_train_images {}\".format(np.shape(alter_brightness_train_images)))\n    print(\"Shape of alter_brightness_train_keypoints {}\".format(np.shape(alter_brightness_train_keypoints)))\n    train_images = np.concatenate((train_images, alter_brightness_train_images))\n    train_keypoints = np.concatenate((train_keypoints, alter_brightness_train_keypoints))\n    fig, axs = plt.subplots()\n    plot_sample(alter_brightness_train_images[0], alter_brightness_train_keypoints[0], axs, \"Altered Brightness\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.051799Z","iopub.status.idle":"2023-01-20T20:10:58.052590Z","shell.execute_reply.started":"2023-01-20T20:10:58.052332Z","shell.execute_reply":"2023-01-20T20:10:58.052356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shift_images(images, keypoints):\n    shifted_images, shifted_keypoints = [], []\n    for shift in config.pixel_shifts:\n        for (shift_x, shift_y) in [(-shift,-shift), (-shift,shift), (shift,-shift), (shift,shift)]:\n            M = np.array([[1, 0, shift_x], [0, 1, shift_y]], dtype=float)\n            for image, keypoint in zip(images, keypoints):\n                shifted_image = cv2.warpAffine(image, M, (96, 96), flags=cv2.INTER_CUBIC)\n                shifted_keypoint = np.array([(point+shift_x) if idx%2==0 else (point+shift_y) for idx, point in enumerate(keypoint)])\n                if np.all(0.0<shifted_keypoint) and np.all(shifted_keypoint<96.0):\n                    shifted_images.append(shifted_image.reshape(96, 96, 1))\n                    shifted_keypoints.append(shifted_keypoint)\n        shifted_keypoints = np.clip(shifted_keypoints, 0.0, 96.0)\n        return shifted_images, shifted_keypoints\n    \nif config.shift_augmentation:\n    shifted_train_images, shifted_train_keypoints = shift_images(clean_train_images, clean_train_keypoints)\n    print(\"Shape of shifted_train_images: {}\".format(np.shape(shifted_train_images)))\n    print(\"Shape of shifted_train_keypoints: {}\".format(np.shape(shifted_train_keypoints)))\n    train_images = np.concatenate((train_images, shifted_train_images))\n    train_keypoints = np.concatenate((train_keypoints, shifted_train_keypoints))\n    fig, axs = plt.subplots()\n    plot_sample(shifted_train_images[0], shifted_train_keypoints[0], axs, \"Shifted Image\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.053985Z","iopub.status.idle":"2023-01-20T20:10:58.054730Z","shell.execute_reply.started":"2023-01-20T20:10:58.054474Z","shell.execute_reply":"2023-01-20T20:10:58.054508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_noise(images):\n    noisy_images = []\n    for image in images:\n        noisy_image = cv2.add(image, 0.008 * np.random.randn(96, 96, 1))\n        noisy_images.append(np.reshape(noisy_image, (96, 96, 1)))\n    return noisy_images\n\nif config.random_noise_augmentation:\n    noisy_train_images = add_noise(clean_train_images)\n    print(\"Shape of noisy_train_images {}\".format(np.shape(noisy_train_images)))\n    train_images = np.concatenate((train_images, noisy_train_images))\n    train_keypoints = np.concatenate((train_keypoints, clean_train_keypoints))\n    fig, axs = plt.subplots()\n    plot_sample(noisy_train_images[0], clean_train_keypoints[0], axs, \"Noisy Image\")","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.056149Z","iopub.status.idle":"2023-01-20T20:10:58.056925Z","shell.execute_reply.started":"2023-01-20T20:10:58.056659Z","shell.execute_reply":"2023-01-20T20:10:58.056683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Shape of train_image: {}\".format(np.shape(train_images)))\nprint(\"Shape of train_keypoints: {}\".format(np.shape(train_keypoints)))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.058292Z","iopub.status.idle":"2023-01-20T20:10:58.059061Z","shell.execute_reply.started":"2023-01-20T20:10:58.058797Z","shell.execute_reply":"2023-01-20T20:10:58.058821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model = tf.keras.applications.ResNet50(input_shape=(96, 96, 3), \n                                                        include_top=False, \n                                                        weights='imagenet')\npretrained_model.trainable = True\n\nlayers = [\n    tf.keras.layers.Conv2D(filters=3,\n                           kernel_size=1,\n                           padding='same',\n                           input_shape=(96, 96, 1)),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    pretrained_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dropout(0.1),\n    tf.keras.layers.Dense(30),\n]\n\nmodel = tf.keras.Sequential(layers, name='keypoints_regression')","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.060448Z","iopub.status.idle":"2023-01-20T20:10:58.061228Z","shell.execute_reply.started":"2023-01-20T20:10:58.060981Z","shell.execute_reply":"2023-01-20T20:10:58.061006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isdir('trained_model'):\n    model = tf.keras.models.load_model('trained_model')\n    train_model = False\nelse:\n    train_model = True\n\ntrain_model = True\n\nprint(\"Training model: {}\".format(train_model))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.062596Z","iopub.status.idle":"2023-01-20T20:10:58.063356Z","shell.execute_reply.started":"2023-01-20T20:10:58.063101Z","shell.execute_reply":"2023-01-20T20:10:58.063125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train_model:\n    es = keras.callbacks.EarlyStopping(\n        monitor='loss',\n        patience=30,\n        verbose=1,\n        mode='min',\n        baseline=None,\n        restore_best_weights=True)\n\n    rlp = keras.callbacks.ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,\n        patience=5,\n        min_lr=1e-15,\n        mode='min',\n        verbose=1)\n    \n    mc = tf.keras.callbacks.ModelCheckpoint(\n        filepath='model.{epoch:02d}-{val_loss:.4f}.h5', \n        save_freq='epoch', verbose=1, monitor='val_loss', \n        save_weights_only=True, save_best_only=True\n    )    \n\n    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'acc'])\n\n    history = model.fit(x=train_images,\n                        y=train_keypoints,\n                        epochs=config.NUM_EPOCHS,\n                        batch_size=config.BATCH_SIZE,\n                        validation_split=0.05,\n                        callbacks=[es, rlp, mc])","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.064779Z","iopub.status.idle":"2023-01-20T20:10:58.065547Z","shell.execute_reply.started":"2023-01-20T20:10:58.065289Z","shell.execute_reply":"2023-01-20T20:10:58.065313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.066925Z","iopub.status.idle":"2023-01-20T20:10:58.067668Z","shell.execute_reply.started":"2023-01-20T20:10:58.067411Z","shell.execute_reply":"2023-01-20T20:10:58.067435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train_model:\n    sns.set_style('darkgrid')\n\n    fig, ax = plt.subplots(3, 1, figsize=(20, 10))\n    df = pd.DataFrame(history.history)\n    df[['mae', 'val_mae']].plot(ax=ax[0])\n    df[['loss', 'val_loss']].plot(ax=ax[1])\n    df[['acc', 'val_acc']].plot(ax=ax[2])\n    ax[0].set_title('Model MAE', fontsize=12)\n    ax[1].set_title('Model Loss', fontsize=12)\n    ax[2].set_title('Model Acc', fontsize=12)\n    fig.suptitle('Modle Metrics', fontsize=18)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.069100Z","iopub.status.idle":"2023-01-20T20:10:58.069876Z","shell.execute_reply.started":"2023-01-20T20:10:58.069605Z","shell.execute_reply":"2023-01-20T20:10:58.069629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ntest_preds = model.predict(test_images)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.071227Z","iopub.status.idle":"2023-01-20T20:10:58.072000Z","shell.execute_reply.started":"2023-01-20T20:10:58.071726Z","shell.execute_reply":"2023-01-20T20:10:58.071751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = test_preds[:, 22:24]\nb = test_preds[:, 24:26]\nmouth_length = np.linalg.norm(a-b, axis=1)\na = test_preds[:, 26:28]\nb - test_preds[:, 28:30]\nmouth_width = np.linalg.norm(a-b, axis=1)\nproportions = np.abs(mouth_width/mouth_length)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.073376Z","iopub.status.idle":"2023-01-20T20:10:58.074142Z","shell.execute_reply.started":"2023-01-20T20:10:58.073901Z","shell.execute_reply":"2023-01-20T20:10:58.073926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20, 16))\nidxs = np.random.choice(test_preds.shape[0], 20)\nprint(idxs)\nfor i, idx in enumerate(idxs):\n    axis = fig.add_subplot(4, 5, i+1, xticks=[], yticks=[])\n    plot_sample(test_images[idx], test_preds[idx], axis, str(proportions[idx]))","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.075629Z","iopub.status.idle":"2023-01-20T20:10:58.076408Z","shell.execute_reply.started":"2023-01-20T20:10:58.076149Z","shell.execute_reply":"2023-01-20T20:10:58.076174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train_model:\n    feature_names = list(idlookup_data['FeatureName'])\n    image_ids = list(idlookup_data['ImageId']-1)\n    row_ids = list(idlookup_data['RowId'])\n\n    feature_list = []\n    for feature in feature_names:\n        feature_list.append(feature_names.index(feature))\n\n    predictions = []\n    for x,y in zip(image_ids, feature_list):\n        predictions.append(test_preds[x][y])\n\n    row_ids = pd.Series(row_ids, name = 'RowId')\n    locations = pd.Series(predictions, name = 'Location')\n    locations = locations.clip(0.0,96.0)\n    submission_result = pd.concat([row_ids,locations],axis = 1)\n    submission_result.to_csv('submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.077799Z","iopub.status.idle":"2023-01-20T20:10:58.078577Z","shell.execute_reply.started":"2023-01-20T20:10:58.078315Z","shell.execute_reply":"2023-01-20T20:10:58.078340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train_model:\n    model.save('trained_model')","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.079976Z","iopub.status.idle":"2023-01-20T20:10:58.080721Z","shell.execute_reply.started":"2023-01-20T20:10:58.080462Z","shell.execute_reply":"2023-01-20T20:10:58.080486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2023-01-20T20:10:58.082103Z","iopub.status.idle":"2023-01-20T20:10:58.082865Z","shell.execute_reply.started":"2023-01-20T20:10:58.082602Z","shell.execute_reply":"2023-01-20T20:10:58.082625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}